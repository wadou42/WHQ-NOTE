## 方法在三款验收软件上的测试
### 模型介绍
模型：二分类模型，模型在训练时未使用redis数据
模型能力：'accuracy': 0.785, 'precision': 0.8659, 'recall': 0.7588, 'f1_score': 0.809
预测使用opt_config(优化配置）来源：从训练集中提取的opt_config，共1670条
投票方式：以热点函数的**执行时间**作为weights，对置信度进行加权平均以此作为排名依据，选出TOP-10

### 搜索方式
以预测出的TOP-10作为搜索的起点，采用随机搜索的方式进行搜索。注意，搜索过程中是采用实际测试而非预测。

### Redis
测试指标-Redis-benchmark :
set: requests=5000000,clients=80 && get: requests=5000000, clients=80

为保证测试的准确性，每一个opt_config执行50次取平均值作为最终的测试结果。并且在50次测试中，每次测试采用opt_config和O3交替执行的方式以最大程度减小环境对于测试结果准确性的影响，逻辑如下：

```python 
# repeat == 50
for _ in range(repeat):
    opt_time += redis_management.test() #测试opt_config
    base_time += redis_management_base.test() #测试O3
return base_time / opt_time
```

测试结果（50轮搜索）：
我们的方法最优值相对于-O3基线提升**10.8%**
之前使用SRTuner与RandomTuer测试结果分别是**2.69% 与 2.64%**

![[redis测试.50repeat.png]] 

### Doris
#### 测试
测试指标-TPCH：开缓存热数据
为保证测试的准确性，每一个opt_config进行测试时会执行**26**次查询测试，其中前**6**轮作为预热，**20**次取平均值作为最终的测试结果。由于doris启动较慢、并且需要预热，因此不采用测试redis时的交替执行。

测试结果（20轮搜索）：
我们的方法没有明显优于-O3的，最好的结果是接近-O3，加速比为**0.996**
SRTuner和RandomTuner的结果分别为**0.917**和**0.927**
![[Aotutunning_doris.png]]

#### 问题分析：
1. doris的热点函数集中在`bucket_find`函数，**超过一半**的执行时间是这个函数。在投票的时候这个函数有“一票否决权”，如果对他预测不准确可能整个项目的预测就不准确。
 ![[Pasted image 20250409161923.png]]
![[bucket_find.png]]
2. 目前向模型输入的opt_configs是来自train set，共1400多个。并且在收集的数据中，正负样本比例（相对于-O3是加速还是减速）大概是2:1。

#### 验证
主要是验证是否存在超过O3的优化选项，以及潜在的可以超过O3的方法。

有三个路线：

1. 尝试在O3的基础上微调关键优化选项
2. doris的不同测试用例是否可以进行划分
3. 尝试将函数调优工具适配在doris上

进度：

任务1 和 任务2 目前属于代码已经写好，正在跑；

任务3 是和redis的适配有一些差异，目前在研究如何适配（有方向但是还没尝试

##### 对doris O3性能差异的分析

-O3下编译执行、测试，共1263次迭代  
min=2454.0   (0.9308217919193884)  
q1=2576.0    (0.9770973659267909)  
q2=2625.0    (0.9956834571264852)  
q3=2680.0    (1.016545396228183)  
max=3026.0   (1.1477859585770454)  
avg=2636.38  (1)  
​  
step=100, the bias of averages are:  
--------------------------------------------------  
2659.1  
0.86%
-------------------------------------------------  
2603.86  
1.23%  
--------------------------------------------------  
2619.19  
0.65%  
--------------------------------------------------  
2617.79  
0.71%  
--------------------------------------------------  
2619.05  
0.66%  
--------------------------------------------------  
2652.58  
0.61%  
--------------------------------------------------  
2658.13  
0.82%  
--------------------------------------------------  
2614.62  
0.83%  
--------------------------------------------------  
2688.45  
1.98%  
--------------------------------------------------  
2576.5  
2.27%  
--------------------------------------------------  
2602.52  
1.28%  
--------------------------------------------------  
2620.59  
0.60%  
--------------------------------------------------  
​  
step=200, the bias of averages are:  
--------------------------------------------------  
2631.48  
0.19%  
--------------------------------------------------  
2618.49  
0.68%  
--------------------------------------------------  
2635.815  
0.02%  
--------------------------------------------------  
2636.375  
0.00%  
--------------------------------------------------  
2632.475  
0.15%  
--------------------------------------------------  
2611.555  
0.94%  
--------------------------------------------------  
​  
step=300, the bias of averages are:  
--------------------------------------------------  
2627.383333333333  
0.34%  
--------------------------------------------------  
2629.806666666667  
0.25%  
--------------------------------------------------  
2653.733333333333  
0.66%  
--------------------------------------------------  
2599.87  
1.38%  
--------------------------------------------------  
​  
step=400, the bias of averages are:  
--------------------------------------------------  
2624.985  
0.43%  
--------------------------------------------------  
2636.095  
0.01%  
--------------------------------------------------  
2622.015  
0.54%  
--------------------------------------------------  
​  
300够用  
400稳妥

**对buggy代码得到数据的分析**

O3性能取1200次执行的平均值，1263；加速比比较好的。  
这次的优化选项组成本身问题就很大，所以生成的选项和O3差的不是特别远。  
​  
12:  2558.1: 3.05%: -fmerge-constants  
161: 2577.6: 2.27%: -fmerge-constants -fstrict-overflow

##### 对【关键优化选项局部搜索】、【测试用例拆分】的实验结果分析

**背景**

什么是【关键优化选项】：以优化全开为基础，关闭某个选项对性能带来的影响越大，某个选项越关键；本次实验选择了**156**个选项中的**33**个作为关键优化选项。

【局部搜索】的策略：将已搜索的关键优化选项集合记为O，确保每次的新选项和O中的选项最小距离最大。

【选项指定】的策略：以O3为基础，加 -f 或 -fno- 前缀的选项。

【测试用例拆分】的原理：doris提供了一系列sql文件作为测试用例，在执行结束后，doris会输出一个统计，记录了每个用例的执行时间。doris会将第一次输出作为cold run结果，最后一次作为hot结果。我的实验中和hongqi保持一致使用了hot run的结果。

q1      265     207     218     207  
q2      90      85      87      85  
q3      114     115     116     115  
q4      89      87      93      87  
q5      145     147     150     147  
q6      51      45      43      43  
q7      139     138     146     138  
q8      176     171     158     158  
q9      186     188     191     188  
q10     145     142     140     140  
q11     172     172     174     172  
q12     71      64      64      64  
q13     179     187     170     170  
q14     50      50      49      49  
q15     101     100     95      95  
q16     111     107     110     107  
q17     113     120     114     114  
q18     225     225     221     221  
q19     106     93      91      91  
q20     182     167     172     167  
q21     219     211     211     211  
q22     173     183     184     183  
Total cold run time: 3102 ms  
Total hot run time: 2952 ms

**注意**：目前的迭代次数（还不到50次）还并不多，是比较初步的结论，仅作参考。

 ##### 结论

1. 【关键优化选项搜索】：罕有能超过O3的优化配置。目前唯一超过O3的选项是：`-O3 -fmerge-constants -fstrict-overflow` 。
    
2. 【测试用例拆分】：优化配置对查询的影响趋同，不存在在任何优化配置下性能都不变的测试用例。
    
3. 【测试用例拆分】：不同测试用例对于优化配置的性能检测能力不同。如果我们需要筛选测试用例的话，那我建议优先选择：加速比 > -10%，且方差较高的组
    
4. 【关键优化选项搜索】：比较重要的优化有：（**注：这个思考方式也许可以用于模型训练数据的构造**）

以下三个优化选项影响较大
-finline  
-fmerge-constants  
-fbit-tests

## SCANN
### SCANN介绍
scann简介：SCANN​​（Scalable Nearest Neighbors）是一种​大规模向量相似度搜索算法​，属于​**​近似最近邻搜索​**​的范畴。

在ann-benchmark上对SCANN进行测试，测试结果如下。下图中每一个点对应一个不同的查询参数，三条线对应三个不同的数据集。横坐标是召回率，纵坐标是查询速度——QPS。 
![[7948cabfb9879f863f4764fb77d41b8.png]]

1. 召回率越低速度越快，数据规模越小速度越快
2. 召回率大于**80%** 才比较有使用价值

执行一次完整的测试需要20+小时，因此需要在给出的测试中选择适当的测试集合，以及超参数。
### 测试指标问题
SOW给的测试指标包括三个数据集
![[hw给的测试指标.png]]

我现在采用的是从 50 +个查询参数中，筛选出4个，他们的召回率分散在0.8 - 1之间。分别计算四个参数下opt对于-O3的加速比，再对加速比求均值，作为测试指标。（下图中注释掉的是ann默认的超参数，未注释的是我们选择进行测试的超参数）
![[Scann查询参数.png]]

大部分情况下，四个超参数下的查询得到的加速比是接近的：
```text
flags / base = 119.49395953240338 / 124.12102978825011 = 0.9627213030399402
flags / base = 430.13271709100974 / 451.1873348128667 = 0.9533350870086158
flags / base = 199.15858604689714 / 206.26822934105576 = 0.9655320486491251
flags / base = 286.62968869529294 / 299.4451147754725 = 0.957202754535539
```

但是也有一些会有这种情况, 在某些查询参数下是优于-O3，某些查询参数下低于-O3（那对于ann-benchmark提供的所有查询超参数呢？）：
```text
flags / base = 109.62593345179255 / 124.12102978825011 = 0.8832180464407512
flags / base = 514.5673657818438 / 451.1873348128667 = 1.140473869895449
flags / base = 198.40039755157784 / 206.26822934105576 = 0.9618563080964408
flags / base = 317.4198737511201 / 299.4451147754725 = 1.060026890033338
```

### 测试
测试指标-AnnBenchmark：在SIFT数据集上选择四个超参数（测试指标中提到的四个）进行测试
由于ann-benchmark进行测试时本身就已经是重复测试取最大值，因此在进行迭代时，每次迭代只进行一次测试，也不使用交替执行。

测试结果（50轮搜索）：
除去异常值后，我们的方法最好的结果加速比为1.0212
SRTuner和RandomTuner的结果分别为
这两个异常值，查看日志发现是因为回归率（k-nn）几乎为零导致的，应该是有些优化配置会破坏算法的正确性。排除这两个异常值之后，最大值是**1.0212**。

![[Autotunning.png]]

和SRTuner50轮对比，可以看到我们的方法提供了一个相对来说比较好的起点，只有一个性能明显低于-O3，其余加速比都在0.9以上。有一定的效果，但是效果也并不十分理想，只有一个超过-O3，两个接近-O3。理想情况下是半数以上超过-O3。
![[AutotunningVSSRTuner.png]]

## 下一步计划
1. 适配函数级调油工具到Doris
2. 扩充数据集
3. 但是search的时候增加对数值型选项的search
4. inline