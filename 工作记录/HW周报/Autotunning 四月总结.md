# 1.方法在三款验收软件上的测试
## 模型介绍
模型：二分类模型，模型在训练时未使用验收软件
模型能力：'accuracy': 0.785, 'precision': 0.8659, 'recall': 0.7588, 'f1_score': 0.809
预测使用的opt_config(优化配置）来源：从训练集中提取的opt_config，共1670条
投票方式：以热点函数的**执行时间**作为weights，对置信度进行加权平均以此作为排名依据，选出TOP-10

## 搜索方式
以预测出的TOP-10作为搜索的起点，采用随机搜索的方式进行搜索。注意，搜索过程中是采用**实际测试**而非预测。

## Redis
测试指标-Redis-benchmark :
set: requests=5000000,clients=80 && get: requests=5000000, clients=80

为保证测试的准确性，每一个opt_config执行50次取平均值作为最终的测试结果。并且在50次测试中，每次测试采用opt_config和O3交替执行的方式以最大程度减小环境对于测试结果准确性的影响，逻辑如下：

```python 
# repeat == 50
for _ in range(repeat):
    opt_time += redis_management.test() #测试opt_config
    base_time += redis_management_base.test() #测试O3
return base_time / opt_time
```

测试结果（50轮搜索）：
我们的方法最优值相对于-O3基线提升**10.8%**
之前使用SRTuner与RandomTuer测试结果分别是**2.69% 与 2.64%**

![[redis测试.50repeat.png]] 

## Doris
### 测试
测试指标-TPCH：开缓存热数据
为保证测试的准确性，每一个opt_config进行测试时会执行**26**次查询测试，其中前**6**轮作为预热，**20**次取平均值作为最终的测试结果。由于doris启动较慢、并且需要预热，因此不采用测试redis时的交替执行。

测试结果（20轮搜索）：
我们的方法没有明显优于-O3的，最好的结果是接近-O3，加速比为**0.996**
SRTuner和RandomTuner的结果分别为**0.917**和**0.927**
![[Aotutunning_doris.png]]

### 问题分析：
1. doris的热点函数集中在`bucket_find`函数，**超过一半**的执行时间是这个函数。在投票的时候这个函数有“一票否决权”，如果对他预测不准确可能整个项目的预测就不准确。
 ![[Pasted image 20250409161923.png]]
 ![[bucket_find.png]]
2. 目前向模型输入的opt_configs是来自train set，共1400多个。并且在收集的数据中，正负样本比例（相对于-O3是加速还是减速）大概是2:1。
### 验证
主要是验证是否存在超过O3的优化选项，以及潜在的可以超过O3的方法。
有三个路线：
1. 尝试在O3的基础上微调关键优化选项
2. doris的不同测试用例是否可以进行划分
3. 尝试将函数调优工具适配在doris上
进度：
任务1 和 任务2 目前属于代码已经写好，正在跑；
任务3 是和redis的适配有一些差异，目前在研究如何适配（有方向但是还没尝试
#### 对doris O3性能差异的分析

-O3下编译执行、测试，共1263次迭代

```bash  
min=2454.0   (0.9308217919193884)  
q1=2576.0    (0.9770973659267909)  
q2=2625.0    (0.9956834571264852)  
q3=2680.0    (1.016545396228183)  
max=3026.0   (1.1477859585770454)  
avg=2636.38  (1)  

step=100, the bias of averages are:
--------------------------------------------------
2659.1
0.86%
--------------------------------------------------
2603.86
1.23%
--------------------------------------------------
2619.19
0.65%
--------------------------------------------------
2617.79
0.71%
--------------------------------------------------
2619.05
0.66%
--------------------------------------------------
2652.58
0.61%
--------------------------------------------------
2658.13
0.82%
--------------------------------------------------
2614.62
0.83%
--------------------------------------------------
2688.45
1.98%
--------------------------------------------------
2576.5
2.27%
--------------------------------------------------
2602.52
1.28%
--------------------------------------------------
2620.59
0.60%
--------------------------------------------------

step=200, the bias of averages are:
--------------------------------------------------
2631.48
0.19%
--------------------------------------------------
2618.49
0.68%
--------------------------------------------------
2635.815
0.02%
--------------------------------------------------
2636.375
0.00%
--------------------------------------------------
2632.475
0.15%
--------------------------------------------------
2611.555
0.94%
--------------------------------------------------

step=300, the bias of averages are:
--------------------------------------------------
2627.383333333333
0.34%
--------------------------------------------------
2629.806666666667
0.25%
--------------------------------------------------
2653.733333333333
0.66%
--------------------------------------------------
2599.87
1.38%
--------------------------------------------------

step=400, the bias of averages are:
--------------------------------------------------
2624.985
0.43%
--------------------------------------------------
2636.095
0.01%
--------------------------------------------------
2622.015
0.54%
--------------------------------------------------

300够用
400稳妥
```
#### 对buggy代码得到数据的分析

```bash
O3性能取1200次执行的平均值，1263；加速比比较好的。
这次的优化选项组成本身问题就很大，所以生成的选项和O3差的不是特别远。

12:  2558.1: 3.05%: -fmerge-constants
161: 2577.6: 2.27%: -fmerge-constants -fstrict-overflow
```

#### 对【关键优化选项局部搜索】、【测试用例拆分】的实验结果分析

**背景**
什么是【关键优化选项】：以优化全开为基础，关闭某个选项对性能带来的影响越大，某个选项越关键；本次实验选择了**156**个选项中的**33**个作为关键优化选项。

【局部搜索】的策略：将已搜索的关键优化选项集合记为O，确保每次的新选项和O中的选项最小距离最大。

【选项指定】的策略：以O3为基础，加 -f 或 -fno- 前缀的选项。

【测试用例拆分】的原理：doris提供了一系列sql文件作为测试用例，在执行结束后，doris会输出一个统计，记录了每个用例的执行时间。doris会将第一次输出作为cold run结果，最后一次作为hot结果。我的实验中和hongqi保持一致使用了hot run的结果。

```bash
q1      265     207     218     207  
q2      90      85      87      85  
q3      114     115     116     115  
q4      89      87      93      87  
q5      145     147     150     147  
q6      51      45      43      43  
q7      139     138     146     138  
q8      176     171     158     158  
q9      186     188     191     188  
q10     145     142     140     140  
q11     172     172     174     172  
q12     71      64      64      64  
q13     179     187     170     170  
q14     50      50      49      49  
q15     101     100     95      95  
q16     111     107     110     107  
q17     113     120     114     114  
q18     225     225     221     221  
q19     106     93      91      91  
q20     182     167     172     167  
q21     219     211     211     211  
q22     173     183     184     183  
Total cold run time: 3102 ms  
Total hot run time: 2952 ms
```



**注意**：目前的迭代次数（还不到50次）还并不多，是比较初步的结论，仅作参考。

 #### 结论

1. 【关键优化选项搜索】：罕有能超过O3的优化配置。目前唯一超过O3的选项是：`-O3 -fmerge-constants -fstrict-overflow` 。
   
2. 【测试用例拆分】：优化配置对查询的影响趋同，不存在在任何优化配置下性能都不变的测试用例。
   
3. 【测试用例拆分】：不同测试用例对于优化配置的性能检测能力不同。如果我们需要筛选测试用例的话，那我建议优先选择：加速比 > -10%，且方差较高的组
   
4. 【关键优化选项搜索】：比较重要的优化有：（**注：这个思考方式也许可以用于模型训练数据的构造**）

以下三个优化选项影响较大
```bash
-finline  
-fmerge-constants  
-fbit-tests
```

## SCANN
### SCANN介绍
scann简介：SCANN​​（Scalable Nearest Neighbors）是一种​大规模向量相似度搜索算法​，属于​**​近似最近邻搜索​**​的范畴。

在ann-benchmark上对SCANN进行测试，测试结果如下。下图中每一个点对应一个不同的查询参数，三条线对应三个不同的数据集。横坐标是召回率，纵坐标是查询速度——QPS。 
![[7948cabfb9879f863f4764fb77d41b8.png]]
1. 召回率越低速度越快，数据规模越小速度越快
2. 召回率大于**80%** 才比较有使用价值

执行一次完整的测试需要20+小时，因此需要在给出的测试中选择适当的测试集合，以及超参数。
### 测试指标问题
SOW给的测试指标包括三个数据集
![[hw给的测试指标.png]]

我现在采用的是从 50 +个查询参数中，筛选出4个，他们的召回率分散在0.8 - 1之间。分别计算四个参数下opt对于-O3的加速比，再对加速比求均值，作为测试指标。（下图中注释掉的是ann默认的超参数，未注释的是我们选择进行测试的超参数）

![[Scann查询参数.png]]

大部分情况下，四个超参数下的查询得到的加速比是接近的：
```text
flags / base = 119.49395953240338 / 124.12102978825011 = 0.9627213030399402
flags / base = 430.13271709100974 / 451.1873348128667 = 0.9533350870086158
flags / base = 199.15858604689714 / 206.26822934105576 = 0.9655320486491251
flags / base = 286.62968869529294 / 299.4451147754725 = 0.957202754535539
```

但是也有一些会有这种情况, 在某些查询参数下是优于-O3，某些查询参数下低于-O3（那对于ann-benchmark提供的所有查询超参数呢？）：
```text
flags / base = 109.6259 / 124.1210 = 0.8832
flags / base = 514.5673 / 451.1873 = 1.1404
flags / base = 198.4003 / 206.2682 = 0.9618
flags / base = 317.4198 / 299.4451 = 1.0600
```

### 测试
测试指标-AnnBenchmark：在SIFT数据集上选择四个超参数（测试指标中提到的四个）进行测试
由于ann-benchmark进行测试时本身就已经是重复测试取最大值，因此在进行迭代时，每次迭代只进行一次测试，也不使用交替执行。

测试结果（50轮搜索）：
除去异常值后，我们的方法最好的结果加速比为1.0212
SRTuner和RandomTuner的结果分别为**1.012**和**1.030**
这两个异常值，查看日志发现是因为回归率（k-nn）几乎为零导致的，应该是有些优化配置会破坏算法的正确性。

![[Autotunning.png]]
和SRTuner50轮对比，可以看到我们的方法提供了一个相对来说比较好的起点，只有一个性能明显低于-O3，其余加速比都在0.9以上。有一定的效果，但是效果也并不十分理想，只有一个超过-O3，两个接近-O3，理想情况下是半数以上超过-O3。

![[AutotunningVSSRTuner.png]]
# 2.函数工具适配问题简述

## 目前的流程

利用这个命令生成`function.yaml`文件：`ai4c-autotune autorun test-coarse-tuning.ini -scf search_space.yaml --stage-order function --time-after-convergence=1` ，而后通过调整`function.yaml`的方式，通过选项进行调优`-fplugin-arg-coarse_option_tuning_plugin_gcc12-autotun`

## 已经发现的问题

1. 编译生成 `opportunity` 时，必须指定单核编译（非常影响适配到大型项目的时间），否则会造成 `opportunity` 文件格式错误。
   
2. 生成的 `opportunity`中，如果包含匿名的namespace，将会造成`opportunity`文件的解析错误。比如（`{anonymous}::`开头）：
```bash
split.cc.yaml:1991:Name: {anonymous}::AppendTo<std::vector<std::__cxx11::basic_string<char> >, strings::internal::Splitter<strings::delimiter::AnyOf, strings::internal::NoFilter> >
```
## 目前的问题

1. 为了加速`function.yaml`的生成过程（单核编译doris非常慢，同时对`opportunity`文件的解析也非常慢，因为`opportunity`文件有**10+G**）；我对AI4C的流程进行了修改，将`OppCompileCommand`的命令替换为将已有的合法`opportunity`文件复制到指定位置。同时，将`RunCommnd`，以及`CompileCommand`都替换成`date`。问题是：这个流程在`redis`上仍然可以正常生成`function.yaml`文件，但是在`doris`上并没有办法正常生成。报错为： 注：可能和doris太大有关（redis的opp只有7.7M，而doris的有12G）
```bash
[2025-04-21 13:24:02,258] WARNING opentuner.search.plugin: no results yet @plugin.py:98
[2025-04-21 13:24:02,263]   ERROR ai4c.autotuner.main: Failed to execute command "autorun".  @main.py:243
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/ai4c/autotuner/main.py", 
  line 231, in run
    self.functions[self.command]()
  File "/usr/local/lib/python3.9/site-packages/ai4c/autotuner/main.py", 
  line 670, in auto_run_main
    tuner.main(self.args,
  File "opentuner/measurement/interface.py", line 300, in main
  File "opentuner/tuningrunmain.py", line 202, in main
AttributeError: 'NoneType' object has no attribute 'configuration'
```
## 目前问题的解决思路

1. 修改AI4C的源码，重新安装，想办法绕过`AttributeError`，直接通过AI4C的源码生成`function.yaml`。这个具有可行性而且生成的`function.yaml`正确性很高。
   
2. 直接研究`redis`的`function.yaml`文件和`opportunity`文件内容之间的关联，自己写一个脚本从opportunity文件生成function.yaml。这个方案生成的function.yaml文件可能会有问题，但是我认为如果指定不同function.yaml构建并运行doris具有显著的性能差异，也可以视为function.yaml生成成功。即，这个方案可能会生成错误的function.yaml文件，但是可以被验证。 P.S. 我看了看`opentuner`加载`opportunity` 并生成`search_space`的方法，我认为可以直接走这个路线。
目前的问题：
# 3.下周计划
1. 继续适配函数级调优工具到Doris
	参考函数工具适配“目前问题解决思路”这一小结
2. 扩充数据集
	过去收集数据集的时候没有考虑到政府杨本平衡的问题，继续收集数据集时适当增加正样本的比例
3. 在Search阶段增加对数值型选项的Search
4. 在Search阶段增加函数级调优工具中优化选项的Search
5. 对预测模型进行一些调整，尝试让模型直接基于代码表征预测关键优化标志的开与关，而非整个优化配置相对于-O3的加速比