### 问题
通过实验，我们发现在现有的搜索空间下（-O3下的所有0-1优化选项），将程序性能提升5% 较为困难，因此目前正在做扩充搜索空间，暂定将搜索空间由`-O3`扩展至`-Ofast`。 扩充主要从两个部分，一是在模型训练，按照新的搜索空间进行重新收集数据训练模型。二是在搜索迭代中，除了01型优化选项外，也考虑数值型优化选项。

### 解决
1. 数据集重新收集
使用新的搜索空间（gcc for openeuler的所有01选项），按照原有的方法，重新收集了cbench、mysql、rocksdb以及新增的faiss四款软件的函数在不同优化配置下的执行时间。

2. 搜索
	将搜索过程的搜索空间拓展为gcc的全部的优化选项（包含0-1类型，和数值类型）
	
3. 约束求解
	在使用新的搜索空间时，出现大量的编译选项导致编译失败。并且在搜索过程中发现，搜索效果很差，大部分组合测试的执行时间是-O3的两倍以上。因此我们基于z3约束求解器，开发了一个约束求解工具，并对其使用方法进行了扩展。
	
	具体的，我们将约束大致分为一下三个级别
	* 编译不通过
	* 编译通过但是执行时间约是-O3的数倍（认为这类优化配置完全没有优化潜力）
	 *  编译通过但是执行时间是-O3的1.5倍以上（认为这类优化配置潜力较低）
	
	依次解决上述约束之后可以大大提高迭代过程中编译选项组合的质量。
	
### 其他工作
1. 调查了不同选项指定方式下scann的性能差异：
	起因是chenyao实现的搜索框架和hongqi实现的搜索框架产生较大的结果差异，经过排查确定差异是由选项指定方式引起：
	方式1（冗余指定）：无论选项在O3下是否默认开启，都会再次指定一次该选项以开启优化；
	方式2（非冗余指定）：若选项在O3下默认开启，则不显示指定该选项以开启优化。
	其中方式1（冗余指定）下，scann会有好的性能表现。

2. IR2VEC适配，完成利用clang-17获取doris、redis的llvm ir获取（选项:-c -S -emit-llvm -O0 -Xclang -disable-O0-optnone）；得到未经优化的IR。目前正在按照函数抽取IR2VEC表征。

3. 使用CodeT5进行直接预测：利用CodeT5、CodeT5p的 encoder-decoder，尝试一下直接基于大模型进行预测，不使用MLP。
	例如：
	-输入`</code>...code...</code> </opt>...opt...</opt>`, 
	-输出 `0` 或者 `1`
	但是因为这些模型的输入有长度限制，因此这个方法目前效果并不明显。

### TODO
- [ ] 对输入维度进行降维，从而提高模型预测的精度
- [ ] 在模型表征这一部分加入专家知识，从而提高对代码表征的能力
- [ ] 完成IR2VEC的IR抽取，并将我们方法中的表征部分替换为IR2VEC进行测试