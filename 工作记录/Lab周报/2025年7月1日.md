### 进展！
**结果展示：**
最好的一组precision = **0.7851** ; recall = 0.5970  (只看pre)
或者precision = 0.7632; recall = 0.7549 （兼顾）
![[Snipaste_2025-07-01_11-07-05.png]]
方法：
```python
 opt_on_tokens = [f"<opt_on_{idx}>" for idx in range(263)]

opt_off_tokens = [f"<opt_off_{idx}>" for idx in range(263)]

        self.tokenizer.add_tokens(opt_on_tokens)

        self.tokenizer.add_tokens(opt_off_tokens)
```