### 进展！
**结果展示：**
最好的一组precision = **0.7851** ; recall = 0.5970  (只看pre)
或者precision = 0.7632; recall = 0.7549 （兼顾）
![[Snipaste_2025-07-01_11-07-05.png]]
方法：
使用T5ForConditionalGeneration用来encoder-decoder

1. 最初使用的是, 但是config的长度太长了。
```python
input_text = (
    "Determine if the optimization below outperforms -O3.\n"
    f"Optimization:\n{config}\n\n"
    f"Code:\n{code}"
)
```
2. 找到一些无用的优化标志、并且使用One-hot编码。但是对于T5来讲，对文本的理解效果更好一些。
3. 将表征替换为单词<opt_on_{idx}> or 
```python
opt_on_tokens = [f"<opt_on_{idx}>" for idx in range(263)]
opt_off_tokens = [f"<opt_off_{idx}>" for idx in range(263)]

self.tokenizer.add_tokens(opt_on_tokens)
self.tokenizer.add_tokens(opt_off_tokens)
```