### 好进展！
**结果展示：**
最好的一组precision = **0.7851** ; recall = 0.5970  (只看pre)
或者precision = 0.7632; recall = 0.7549 （兼顾）
![[Snipaste_2025-07-01_11-07-05.png]]
方法：
使用T5ForConditionalGeneration用来encoder-decoder

1. 最初使用的是, 但是config的长度太长了。
```python
input_text = (
    "Determine if the optimization below outperforms -O3.\n"
    f"Optimization:\n{config}\n\n"
    f"Code:\n{code}"
)
```
2. 找到一些无用的优化标志、并且使用One-hot编码。但是对于T5来讲，对文本的理解效果更好一些。
3. 将表征替换为单词<opt_on_{idx}> or <opt_off_{idx}>并加入到分词器中，这样每一个词只用一个token。
```python
opt_on_tokens = [f"<opt_on_{idx}>" for idx in range(263)]
opt_off_tokens = [f"<opt_off_{idx}>" for idx in range(263)]

self.tokenizer.add_tokens(opt_on_tokens)
self.tokenizer.add_tokens(opt_off_tokens)
```


### 其余工作：
1. redis/scann/doris三款软件的-O3下性能收集完成

2. redis/scann 在srtuenr下的性能收集完成
	1. redis三次分别为4.2%、4.6%、3.4%
	2. scann三次分别为1.4%、0.9%、0.2%
	3. doris 测试了一次，劣于-O3 [TODO]

3. doris build的约束找完了，也就是可以保证doris的测试成功。但是启动和测试不一定可行...  [TODO]

### TODO
模型
测试