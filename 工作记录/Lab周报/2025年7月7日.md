## 方案介绍
方案主要分为两个部分，基于代码表征的预测模块与基于预测结果的搜索模块。其中，基于代码表征的预测模块通过预测得出比较优秀的一组优化配置；搜索部分以此为起点进行局部搜索，得到最优的优化配置。

具体的，基于代码表征的预测模块采用CodeT5的一个变种——T5ForCondictionGeneration作为代码表征与二分类模型。将 ​**​函数代码 + 优化选项组合​**​ 作为输入，预测该优化组合是否比 `-O3` 更优（输出 `1` 表示优于 `-O3`，`0` 表示不优于）

我们的输入采用以下的结构，其中code直接使用源码作为输入，将优化选项（如 `-flto`、`-funroll-loops`）编码为自定义 Token（如 `<opt_42_on>` 表示第 42 个选项启用）

```python
input_text = ( 
	"Strictly classify if this optimization is better than -O3. If uncertain, answer '0'.\n" 
	f"Optimization:\n{config}\n" 
	f"Code:\n{code}" 
)
```

在微调训练过程中，扩展分词器词汇表（添加 `<opt_*_on/off>` Token）， 同时微调encoder和decoder的后几层（这里采用的是后4层）。最终，模型输出‘0’或者‘1’。
```python
opt_on_tokens = [f"<opt_on_{idx}>" for idx in range(263)]
opt_off_tokens = [f"<opt_off_{idx}>" for idx in range(263)]

self.tokenizer.add_tokens(opt_on_tokens)
self.tokenizer.add_tokens(opt_off_tokens)

model.resize_token_embeddings(len(self.tokenizer))	
```

