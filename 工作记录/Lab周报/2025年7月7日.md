## 方案介绍
方案主要分为两个部分，基于代码表征的预测模块与基于预测结果的搜索模块。其中，基于代码表征的预测模块通过预测得出比较优秀的一组优化配置；搜索部分以此为起点进行局部搜索，得到最优的优化配置。

### 基于代码表征的预测模块
**模型微调**

具体的，该模块采用CodeT5的一个变种——T5ForCondictionGeneration作为代码表征与二分类模型。将 ​**​函数代码 + 优化选项组合​**​ 作为输入，预测该优化组合是否比 `-O3` 更优（输出 `1` 表示优于 `-O3`，`0` 表示不优于）

我们构造的输入是一个自然语言提示（prompt）形式的文本，将**优化配置（config)** 和**函数代码（code）** 统一编码：

```python
input_text = ( 
	"Strictly classify if this optimization is better than -O3. If uncertain, answer '0'.\n" 
	f"Optimization:\n{config}\n" 
	f"Code:\n{code}" 
)
```

其中：
- **config** 是优化选项的 one-hot 编码（通过 `<opt_42_on>` 或 `<opt_42_off>` 的 token 表示），并按字典序排列，增加结构一致性。
    
- 将 `<opt_XX_on/off>` token 加入 T5 的词表，确保模型理解它们的语义。
	```python
	opt_on_tokens = [f"<opt_on_{idx}>" for idx in range(263)]
	opt_off_tokens = [f"<opt_off_{idx}>" for idx in range(263)]
	
	self.tokenizer.add_tokens(opt_on_tokens)
	self.tokenizer.add_tokens(opt_off_tokens)
	
	model.resize_token_embeddings(len(self.tokenizer))	
	```
    
- 模型使用 **`T5ForConditionalGeneration`** 微调，以学习从输入的代码+优化配置到“是否优于 -O3”的映射，使用 T5 的 `encoder-decoder` 架构生成 **`0` 或 `1`** 的预测输出，表示是否优于 `-O3`。

**基于模型预测**

我们首先从训练集中提取了 6,000 多条优化配置（每条配置是多个编译器优化选项的组合）。同时，从待调优的目标程序中提取热点函数，作为评估对象。

然后我们构造所有“优化配置 × 热点函数”的组合，输入到已微调的 T5ForCondictionGeneration 预测模型中，模型会输出每个组合在该配置下是否优于 `-O3` 的概率（即置信度）。

对于每个优化配置，我们对其在所有热点函数上的预测置信度进行加权平均，权重为热点函数的执行时间（越耗时越重要）。这个加权平均值用于衡量该配置的整体潜力。

最后，我们根据加权得分对所有配置进行排序，选取前 10 个置信度最高的配置，作为搜索模块的搜索起点，用于后续的性能调优过程。

**为何选择T5ForCondictiongeneration？**
1. T5ForCondictiongeneration 类模型是为**文本到文本**任务设计的通用模型，能很好地理解上下文中的结构性自然语言提示，也容易理解代码的语义信息。

2. T5 模型允许我们向分词器中加入自定义的 token，例如 `<opt_42_on>`、`<opt_42_off>` 等，并在微调过程中共同学习这些 token 的语义。这种机制使模型能够更深入地理解优化选项的结构和含义。虽然 BERT 类模型在技术上也支持加入自定义 token，但由于其 encoder-only 的架构和预训练方式限制，这些 token 的语义更难在微调中充分学习；而 T5 模型的 seq2seq 结构更适合表达结构化输入和 prompt，并能更有效地融合这些 token 的含义。

3. T5 采用 seq2seq 架构，我们预测 `0` 或 `1`，将来如果需要扩展为多分类任务（如输出 `0` / `1` / `2`，或解释性文字），T5 的 decoder 可以直接生成目标序列，而无需结构修改。

### 搜索模块
以预测模块的结果为基础，进行局部搜索。

**约束预处理**
我们采用的搜索空间是gcc所有的0-1选项，但大部分程序无法在所有的优化组合下编译、运行成功，我们将无法编译、运行的最小优化组合成为约束。 

为了解决这一问题，我们基于z3约束求解器，实现了约束自动求解工具，可以实现约束的自动求解。

**搜索**


## 评估与测试
### `-O3`
1. redis
由于redis是单线程程序，所以其执行效率与在哪个cpu核执行有很大的关系，因此为了避免该因素的影响，redis-server在319核上运行，redis-benchmark在318核上运行。

重复100次执行，选择中位数作为最终的测试结果，最终redis在`-O3`执行时间为18.7741ms

2. doris
限制在128核，重复100次执行，选择中位数作为最终的测试结果，最终doris在`-O3`执行时间为2519.5ms

3. scann
限制在128核，重复100次执行，选择中位数作为最终的测试结果，最终scann在`-O3`qps为 457.586

### SRTuner
与测试-O3时采用同样的环境，测试限制在测试时间24小时，迭代轮次50轮。SRTuner测试使用的搜索空间为其自带的gcc_opt.txt。在此基础上，我们排除了一些常见的约束，例如当`-ftoplevel-reorder`关闭的时候，`-fsection-anchors `必须关闭，然后进行迭代搜索。在搜索过程中，-O3的执行时间默认不变为前面测试的结果。
1. redis
