代码实现部分

~~~python
import xlrd
import math

# coding=utf-8

#第一步，记录所有的词库里的分割方法
print("Reading dictionary...")
dic_words = []

workbook = xlrd.open_workbook("./综合类中文词库.xlsx")
booksheet = workbook.sheet_by_index(0)
rows = booksheet.get_rows()
for row in rows :
    dic_words.append(row[0].value)

print("Finished")
print("dic_word len:" + str(len(dic_words)))

# 下面是一个单词出现的概率，为了简化问题，我只列出很小一部分的单词的概率
#  未出现的单词的概率设置为0.00001
#  这里我们是手动输入的概率，在实际的应用中可以统计得来
word_prob = {"今天" : 0.03, "的" : 0.08, "作" : 0.005, "业" : 0.005,"作业" : 0.06,"有点" : 0.04, "难" : 0.05}

print(sum(word_prob.values()))

#因为概率连乘会导致概率“等于零”的情况，所以我们把他转化为-log(X)
for word in word_prob.keys():
    word_prob[word] = round(-math.log(word_prob[word]),1)

#第二步，实现字符串的所有分割
def word_break(s,dic):
    def sentences(cur):
        result = []
        if cur < len(s):
            for next in range(cur + 1, len(s) + 1):
                if s[cur:next] in dic:
                    result = result + [s[cur:next] + (tail and ',' + tail) for tail in sentences(next)]
        else:
            return ['']
        return result

    list_new = []
    for line in sentences(0):
        line = line.split(",")
        list_new.append(line)
    return list_new

#  第三步找到最优的分割方式
def word_segment_naive(input_str):

    segments = word_break(input_str,dic_words)  #这里保存了媳妇的所有分割
    #循环所有的分割找到概率最大的分词结果即可
    best_segment = []
    best_score = math.inf
    for seg in segments:
        score = 0
        for word in seg:
            if word in word_prob.keys():
                score += word_prob[word]
            else:
                score += round(-math.log(0.00001),1)
        if score < best_score:
            best_score = score
            best_segment = seg
    
    return best_segment

print(word_segment_naive("今天的作业有点难"))
~~~

![image-20221120170226086](C:\Users\50874\AppData\Roaming\Typora\typora-user-images\image-20221120170226086.png)

这里是运行结果
