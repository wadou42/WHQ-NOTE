## 实验结果

| 软件\方法  | benchmark       | 参数设置                |     |
| ------ | --------------- | ------------------- | --- |
| redis  | redis-benchmark | 10000w get,set      |     |
| doris  | tpch            | 10GB data           |     |
| scann  | ann-benchmark   |                     |     |
| zstd?  | test.json       | level 3             |     |
| mysql? | sysbench        | 64 * 100w, readonly |     |
|        |                 |                     |     |


|   软件\方法   |            Our             |              O3              |             SRTuner             |        ir2vec        | 提升    |
| :-------: | :------------------------: | :--------------------------: | :-----------------------------: | :------------------: | ----- |
|   redis   | 2663857.25<br>（16.81%, 32） |       2280410.25 (qps)       |    2174091.5<br>（-4.6%, 19）     |          重测          | 16.81 |
|   doris   |   2099.0<br>(15.15%, 39)   |         2417.0 (ms)          | 2687.0<br>（-5.03% , 42）<br>正在重测 |         重测？          | 15.15 |
|   scann   |  500.4221<br>(9.26%, 19)   |        457.5862 (qps)        |      461.77<br>（0.91%, 11)      | 452.09<br>（1.20%,23） | 8.06  |
|   zstd?   |      236<br>1.724% ?       |           232 MB/s           |              今天重测               |          待测          | 1.724 |
|  mysql?   |                            | 11578.53<br>(PGO :14093.52 ) |      约11578.53<br>(0 %, )       |                      |       |
|  rocksdb  |           1.xx%            |                              |                                 |                      |       |
| Total Acc |           41.22%           |                              |                                 |                      |       |





## Last Todo
1. 代码整理完成，但是需要在920 上测试下model部分
2. 文档整理
3. 最后两款验收软件测试
4. 一些项目baseline测试

## Presentative
1. 我们方法代码已经测试整理完成，并且在cpu上可以一小时之内完成测试（通过多cpu并行）

|        软件\方法        |            Our             |        O3        |            SRTuner            |        ir2vec        | 提升    |
| :-----------------: | :------------------------: | :--------------: | :---------------------------: | :------------------: | ----- |
|        redis        | 2663857.25<br>（16.81%, 32） | 2280410.25 (qps) | ==2174091.5<br>（-4.67%, 19）== |          重测          | 16.81 |
|        doris        |   2099.0<br>(15.15%, 39)   |   2417.0 (ms)    |  ==2609.0<br>（-7.36% , 8）==   |         重测？          | 15.15 |
|        scann        |  500.4221<br>(9.26%, 19)   |  457.5862 (qps)  |     461.77<br>（0.91%, 11)     | 452.09<br>（1.20%,23） | 8.06  |
|        zstd         |      236<br>1.724% ?       |     232 MB/s     |            ==235==            |          待测          | 1.724 |
| ==**zstd-level5**== |         ==**85**==         | ==**82 MB/s**==  |     ==**80<br>（-2.4%）**==     |       待测（需要ir）       |       |
|       rocksdb       |           1.xx%            |                  |                               |                      |       |
|      Total Acc      |           41.22%           |                  |                               |                      |       |
|                     |                            |                  |                               |                      |       |

2. baseline方法--ir2vec 更改成新的模型
	已经实现，需要预测—>测试  代码已经完整，挂上就行

3. 文档：还没有开始... 但是应该不难
4. 最后一个验收软件：snappy？可能是.

5. 论文baseline：programl —— 利用docker搭建个环境
## New Todo
- [ ] 周三 将ir2vec的代码整理完成，挂上三款验收软件的search
- [ ] 周四 茶思屋测试snappy-SRTuner-our method-ir2vec
- [ ] 周五、周六解决文档问题







1. 为什么是用Unixcode？
 主要候选的有CodeT5  更适合文本生成，不适合表征任务。
 graphcodebert则需要DFG输入，但是输入的token有限，因此效果不够好，而且gpb的预训练数据中不包含c++可能无法理解c++复杂的模板。
 Unixcode是在训练的时候是包含c++的。UniXcoder 的分词器（Tokenizer）经过优化，能比早期的 CodeBERT 更精简地表示 C 家族语言
 UniXcoder 采用了**对比学习（Contrastive Learning）**，使代码的表征空间分布更加均匀。
- **对你的意义**：这种特性使得模型对“代码微调”非常敏感。当你改变一个优化选项标签（如从 `<opt_on_42>` 到 `<opt_on_O3>`）时，UniXcoder 在 Embedding 空间中能够更灵敏地捕获这种配置变化带来的语义漂移，从而提高二分类的置信度准确性。